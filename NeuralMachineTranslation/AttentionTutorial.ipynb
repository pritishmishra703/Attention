{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73483920-3753-44b3-bee1-60733439d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1918bb3a-70aa-4ed1-9ad1-d02316c362b0",
   "metadata": {},
   "source": [
    "#### **Calculating Alignment Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6a64e46-54a7-46db-85d2-69c3f7065590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generating English and Hindi hidden states randomly\n",
    "# Note: In real life, the English hidden states will come from Encoder\n",
    "# and Hindi hidden states from Decoder. As discussed in video.\n",
    "\n",
    "query = tf.random.normal(shape=(1, 1, 5)) # Hindi\n",
    "key   = tf.random.normal(shape=(1, 4, 5)) # English\n",
    "value = tf.identity(key)\n",
    "\n",
    "# In our case, both key and value our same and in most of the cases\n",
    "# it will. So, we just take copy of key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "623e3186-70a1-4fe4-916c-52b3849d4331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Encoder hidden states aka Values/Keys (English):\n",
      "\n",
      "tf.Tensor(\n",
      "[[[-0.1684307   1.514977    0.30911526  0.28211853 -0.5899976 ]\n",
      "  [ 0.72271234  0.34328577  2.1250117   0.4584276  -0.03841743]\n",
      "  [-0.40992028  1.2130448   1.1727004   0.49861977 -0.5706304 ]\n",
      "  [ 0.73742425  0.78300256 -0.8456602   1.0013999  -2.2714462 ]]], shape=(1, 4, 5), dtype=float32)\n",
      "\n",
      "\n",
      "This is Decoder hidden states aka Query (Hindi):\n",
      "\n",
      "tf.Tensor([[[-1.3075145   0.0388818   0.46266425  0.5267501  -0.28575605]]], shape=(1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('This is Encoder hidden states aka Values/Keys (English):\\n')\n",
    "print(key)\n",
    "\n",
    "print('\\n\\nThis is Decoder hidden states aka Query (Hindi):\\n')\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50f34a0c-254b-4d82-af68-3510e282c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Pass it through a Dense layer\n",
    "\n",
    "W_k = tf.keras.layers.Dense(8) # Encoder dense layer\n",
    "W_q = tf.keras.layers.Dense(8) # Decoder dense layer\n",
    "\n",
    "query = W_q(query)\n",
    "key   = W_k(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01e08712-94e9-4537-8aee-c12a3f4b98b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Encoder hidden states (English) after Dense layer:\n",
      "\n",
      "tf.Tensor(\n",
      "[[[-0.24756703  0.5097544  -0.8054534   0.38278162  0.40553892\n",
      "    0.7584797   0.9631532  -0.05434626]\n",
      "  [ 0.74450785  0.39345014 -0.77214    -0.44951338  1.1595069\n",
      "    1.0923375  -0.7526716   1.3522831 ]\n",
      "  [ 0.06857663  0.63732237 -1.35146    -0.25373182  0.70769745\n",
      "    0.71159935  0.51920086  0.78572273]\n",
      "  [ 0.5321673   1.5415154  -0.8645557   0.08788854  0.7075511\n",
      "    1.6135309   2.7103612   0.93703866]]], shape=(1, 4, 8), dtype=float32)\n",
      "\n",
      "\n",
      "This is Decoder hidden states (Hindi) after Dense layer:\n",
      "\n",
      "tf.Tensor(\n",
      "[[[-0.29549062 -0.64636946 -0.5411916   0.39083678 -0.3006574\n",
      "    0.7367449  -0.54453605  0.8530547 ]]], shape=(1, 1, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('This is Encoder hidden states (English) after Dense layer:\\n')\n",
    "print(key)\n",
    "\n",
    "print('\\n\\nThis is Decoder hidden states (Hindi) after Dense layer:\\n')\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f55a4ac-bac8-4a69-a360-b400ab68387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Sum the query and key\n",
    "# You can't do it directly like 'query + key'\n",
    "# We want the output in the shape \n",
    "# (batch_size, no. words hindi, no. words english, units)\n",
    "# (1         , 1              , 4                , 8   )\n",
    "# That's why, first we expand_dims at desired axis:\n",
    "\n",
    "query = tf.expand_dims(query, axis=2)\n",
    "key   = tf.expand_dims(key, axis=1)\n",
    "\n",
    "query_plus_key = tf.nn.tanh(query + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1156edd-aa7d-42a3-a9a0-cc7053bbafe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After sum of query and key:\n",
      "\n",
      "tf.Tensor(\n",
      "[[[[-0.49529898 -0.13577142 -0.8732591   0.6490286   0.10449863\n",
      "     0.90428156  0.3957648   0.66331416]\n",
      "   [ 0.42109084 -0.24766086 -0.865116   -0.05860934  0.69566447\n",
      "     0.9497362  -0.86100256  0.9759976 ]\n",
      "   [-0.22309794 -0.00904684 -0.95560384  0.13625225  0.38595653\n",
      "     0.89536494 -0.02532977  0.9273015 ]\n",
      "   [ 0.23235427  0.71392614 -0.8865877   0.44522214  0.385832\n",
      "     0.9819833   0.97404945  0.9457703 ]]]], shape=(1, 1, 4, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('After sum of query and key:\\n')\n",
    "print(query_plus_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f02cffb3-1551-4c44-bafe-8c9d2bfb805f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 4, 1)\n",
      "(1, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: We don't need that last units axis now, that's why we will\n",
    "# pass `query_plus_key` through a single neuron layer and get rid of that.\n",
    "\n",
    "single_neuron = tf.keras.layers.Dense(1) # single neuron layer\n",
    "\n",
    "score = single_neuron(query_plus_key)\n",
    "print(score.shape)\n",
    "\n",
    "# last shape is simply '1' we will squeeze that to get the final Score\n",
    "score = tf.squeeze(score, -1)\n",
    "print(score.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fcf0b6-bca9-4046-926a-41e005e20b6a",
   "metadata": {},
   "source": [
    "Always remember, the score should always be in this shape:\n",
    "\n",
    "`(batch_size, query.shape[1], key.shape[1])`\n",
    "\n",
    "Then only we can calculate attention weights that's why there are many shape transformations in Bahdanau Attention so the final score is in the desired shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36d0ad75-e0b1-4eda-974e-2985ea6f9707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Alignment Score:\n",
      "\n",
      "tf.Tensor([[[-1.2186558 -0.8982853 -1.1886255 -2.804868 ]]], shape=(1, 1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('Final Alignment Score:\\n')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18a799e-a575-4530-a559-db9b999a4d70",
   "metadata": {},
   "source": [
    "#### **Calculating Attention Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96f472c3-96cb-485c-8fbf-145cf0ae50c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[0.27679184 0.38131896 0.28523007 0.05665916]]], shape=(1, 1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "attention_weights = tf.nn.softmax(score, -1)\n",
    "\n",
    "print(attention_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5316dc75-b48e-4967-9145-246707e7653b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(tf.squeeze(attention_weights, 0), cmap='Reds')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0894b5b0-e200-402a-87e4-598c1add3fff",
   "metadata": {},
   "source": [
    "#### **Calculating Context Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c45838d1-cd67-41d6-99f1-c9862cba0808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[ 0.15382393  0.9405958   1.1824429   0.45185506 -0.46941498]]], shape=(1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "context_vector = tf.matmul(attention_weights, value)\n",
    "\n",
    "print(context_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
